# GuidePoint_NAN

**AI-Powered Indoor Navigation for the Visually Impaired**

A collaborative project between **B.V. Raju Institute of Technology (BVRIT), India** and **The University of Texas at Dallas (UTD), USA**

---

## Problem Statement

Visually impaired individuals face significant challenges navigating indoor spaces due to the lack of reliable, real-time localization systems. Unlike outdoor environments that rely on GPS, indoor areas like hospitals, college campuses, malls, and offices lack structured, accessible guidance infrastructure.

---

## Project Overview

GuidePoint is an assistive technology solution that enables visually impaired users to navigate indoor environments using AI-based localization and voice guidance. The system uses smartphone cameras and sensors to determine the user's location and provide turn-by-turn navigation instructions.

### Key Features

- **AI-Based Indoor Localization** - Uses camera + IMU sensors to track position without GPS
- **Visual Positioning System (VPS)** - Leverages SLAM for live indoor tracking
- **Voice-Based Navigation** - Natural language step-by-step guidance
- **Pathfinding** - A* algorithm for optimal route calculation
- **Offline Functionality** - Works without internet after map download

---

## Repository Structure

This repository combines **BVRIT's Flutter app** with **UTD's AI/ML development**:

```
GuidePoint_NAN/
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ requirements.txt                 # Python ML dependencies
â”‚
â”œâ”€â”€ flutter_app/                     # BVRIT's Flutter Application
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ main.dart               # App entry point
â”‚   â”‚   â””â”€â”€ Screens/
â”‚   â”‚       â”œâ”€â”€ astar_pathfinding.dart    # A* algorithm âœ…
â”‚   â”‚       â”œâ”€â”€ qr_scanner_screen.dart    # QR + voice input
â”‚   â”‚       â”œâ”€â”€ stored_data_screen.dart   # Navigation + TTS
â”‚   â”‚       â””â”€â”€ terms_screen.dart         # First-launch T&C
â”‚   â”œâ”€â”€ android/                    # Android platform
â”‚   â”œâ”€â”€ ios/                        # iOS platform
â”‚   â”œâ”€â”€ pubspec.yaml                # Flutter dependencies
â”‚   â””â”€â”€ README.md                   # Flutter app docs
â”‚
â”œâ”€â”€ models/                          # AI/ML Models
â”‚   â”œâ”€â”€ yolo/                       # BVRIT's YOLO Object Detection
â”‚   â”‚   â”œâ”€â”€ best.pt                 # PyTorch weights
â”‚   â”‚   â”œâ”€â”€ best.onnx               # ONNX format
â”‚   â”‚   â”œâ”€â”€ best_saved_model/       # TFLite models
â”‚   â”‚   â”‚   â”œâ”€â”€ best_float32.tflite # Mobile-ready model
â”‚   â”‚   â”‚   â””â”€â”€ best_float16.tflite # Optimized model
â”‚   â”‚   â”œâ”€â”€ evaluation/             # Training metrics & plots
â”‚   â”‚   â”œâ”€â”€ data.yaml               # Dataset config
â”‚   â”‚   â””â”€â”€ README.md               # Model documentation
â”‚   â”œâ”€â”€ training/                   # UTD: Model training scripts
â”‚   â””â”€â”€ tflite/                     # UTD: Scene classification models
â”‚
â”œâ”€â”€ navigation/                      # UTD: Navigation algorithms
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/                     # Training images
â”‚   â””â”€â”€ maps/
â”‚       â””â”€â”€ ATL JSON.json           # Sample building map
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â””â”€â”€ bvrit_progress/             # BVRIT evaluation results
â”‚
â””â”€â”€ tests/                          # Unit tests
```

---

## Current Implementation Status

### BVRIT Contributions âœ…

| Component | Status | Description |
|-----------|--------|-------------|
| Flutter App | âœ… Complete | Cross-platform mobile application |
| QR Scanner | âœ… Complete | `mobile_scanner` integration |
| A* Pathfinding | âœ… Complete | Full Dart implementation |
| Voice Input | âœ… Complete | `speech_to_text` integration |
| Voice Output (TTS) | âœ… Complete | `flutter_tts` integration |
| Map Parser | âœ… Complete | JSON building layout support |

### UTD Responsibilities ğŸ¯

| Component | Status | Description |
|-----------|--------|-------------|
| YOLO Model | Trained | 16-class object detection |
| Scene Classification CNN | â³ Pending | Identify rooms from camera |
| Model Training Pipeline | â³ Pending | TensorFlow training scripts |
| TFLite Conversion | âœ… Done | Mobile-optimized models |
| Location Detection | â³ Pending | Replace hardcoded start point |
| Enhanced NLP | â³ Pending | Better intent parsing |

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FLUTTER APPLICATION                         â”‚
â”‚                         (flutter_app/)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   QR Scanner    â”‚   Voice I/O     â”‚   A* Navigation             â”‚
â”‚   (Camera)      â”‚   (STT/TTS)     â”‚   (Pathfinding)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                       â”‚
         â–¼                 â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AI MODELS                                â”‚
â”‚                          (models/)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   YOLO          â”‚   Scene CNN     â”‚   Intent Parser             â”‚
â”‚   (Object Det.) â”‚   (Location)    â”‚   (NLP)                     â”‚
â”‚   âœ… BVRIT      â”‚   ğŸ¯ UTD        â”‚   ğŸ¯ UTD                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BUILDING MAPS                               â”‚
â”‚                       (data/maps/)                               â”‚
â”‚                  JSON: nodes, edges, floors                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

### Run Flutter App

```bash
cd flutter_app
flutter pub get
flutter run
```

### Test YOLO Model

```bash
cd models/yolo
pip install ultralytics
python demo_folder.py
```

### Setup ML Development (UTD)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## Tech Stack

| Layer | Technology | Team |
|-------|------------|------|
| **Mobile App** | Flutter (Dart) | BVRIT âœ… |
| **QR Scanning** | `mobile_scanner` | BVRIT âœ… |
| **Pathfinding** | A* (Dart) | BVRIT âœ… |
| **Voice Input** | `speech_to_text` | BVRIT âœ… |
| **Voice Output** | `flutter_tts` | BVRIT âœ… |
| **Object Detection** | YOLOv8 (TFLite) | BVRIT âœ… |
| **Scene Classification** | CNN (TFLite) | UTD ğŸ¯ |
| **Model Training** | TensorFlow/PyTorch | UTD ğŸ¯ |
| **Map Format** | JSON | Joint |

---

## Map JSON Format

```json
{
  "building": {
    "name": "ATL",
    "floors": [{
      "floor_number": 1,
      "nodes": [
        {"id": "main_entrance", "name": "Main Entrance", "position": [0, 0]},
        {"id": "seminar_hall", "name": "Seminar Hall", "position": [4, 3]}
      ],
      "edges": [
        {"from_id": "main_entrance", "to_id": "junction_1", "distance": 3}
      ]
    }]
  }
}
```

---

## UTD Semester Goals

1. **Research** ML models for indoor scene recognition
2. **Develop** CNN architecture for room/zone classification
3. **Train** model on labeled indoor environment images
4. **Convert** to TensorFlow Lite for mobile deployment
5. **Integrate** with Flutter app via `tflite_flutter`

---

## Key Integration Point

The Flutter app currently has a **hardcoded start location**:

```dart
// In qr_scanner_screen.dart
const String startId = 'main_entrance';  // â† REPLACE WITH AI
```

**UTD's Goal:** Build a CNN that outputs the current location ID based on camera input, replacing this hardcoded value.

---

## Contributors

### BVRIT Team
- Kishore-2013
- saikarthikbattula
- Keerthika0510
- SaarthakMaheshuni

### UTD Team
- khaledalshiddi
- nandanpabolu
- [Add team members]

---

## References

- **BVRIT Original Repo:** [Kishore-2013/Guide_Point](https://github.com/Kishore-2013/Guide_Point)
- **Roboflow Dataset:** [Object Detection Dataset](https://universe.roboflow.com/object-detection-fpevm/my-first-project-frvbt/dataset/5)

---

## License

This project is developed as part of the **UTDesign EPICS** program at The University of Texas at Dallas.
